{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba125687",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Appendix: Elements of Probability Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64232c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6409b5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<hr>\n",
    "\n",
    "**Sample Space**\n",
    "<br>\n",
    "The set of all possible outcomes of an experiment is called the *sample space* and is denoted by $\\Omega$.\n",
    "\n",
    "$Events$ are defined as subsets of the sample space.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0414d57",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**$\\sigma$-algebra**\n",
    "<br>\n",
    "A collection $\\mathcal{F}$ of sets in $\\Omega$ is called a *$\\sigma$-algebra* on $\\Omega$ if\n",
    "\n",
    "1. $\\emptyset \\in \\mathcal{F}$;\n",
    "2. if $A \\in \\mathcal{F}$, then $A^c \\in \\mathcal{F}$;\n",
    "3. if $A_1, A_2, \\ldots \\in \\mathcal{F}$, then $\\cup_{i = 1}^\\infty A_i \\in \\mathcal{F}$.\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead735c9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Generated $\\sigma$-algebra**\n",
    "<br>\n",
    "The intersection of all the $\\sigma$-algebras containing $\\mathcal{F}$, denoted $\\sigma(\\mathcal{F})$, is a $\\sigma$-algebra that we call the *$\\sigma$-algebra generated by $\\mathcal{F}$*.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8034498b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Borel $\\sigma$-algebra**\n",
    "<br>\n",
    "Let $\\Omega = \\mathbb{R}^p$. The $\\sigma$-algebra generated by the open subsets of $\\mathbb{R}^p$ is called the *Borel $\\sigma$-algebra* of $\\mathbb{R}^p$ and is denoted by $\\mathcal{B}(\\mathbb{R}^p)$.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a492d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The $\\sigma$-algebra of a sample space contains all possible outcomes of the experiment that we want to study.\n",
    "\n",
    "Intuitively, the $\\sigma$-algebra contains all the useful information that is available about the random experiment that we are performing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbe805d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Probability Measure**\n",
    "<br>\n",
    "A probability measure $\\mathbb{P}$ on the measurable space $(\\Omega, \\mathcal{F})$ is a function $\\mathbb{P}: \\mathcal{F} \\to [0, 1]$ satisfying\n",
    "\n",
    "1. $\\mathbb{P}(\\emptyset) = 0$, $\\mathbb{P}(\\Omega) = 1$;\n",
    "2. For $A_1, A_2, \\ldots$ with $A_i \\cap A_j = \\emptyset$, $i \\ne  j$, then\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{P}(\\cup_{i = 1}^\\infty A_i) = \\sum_{i = 1}^\\infty \\mathbb{P}(A_i)\n",
    "\\end{equation}\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e624313d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Probability Space**\n",
    "<br>\n",
    "The triple $(\\Omega, \\mathcal{F}, \\mathbb{P})$ comprising a set $\\Omega$, a $\\sigma$-algebra $\\mathcal{F}$ of subsets of $\\Omega$ and a probability measure $\\mathbb{P}$ on $(\\Omega, \\mathcal{F})$ is called a *probability space*.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaa047d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Independent Sets**\n",
    "<br>\n",
    "The sets $A$ and $B$ are $independent$ if\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B).\n",
    "\\end{equation}\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d8173",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520f9972",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<hr>\n",
    "\n",
    "**Measurable Space**\n",
    "<br>\n",
    "A sample space $\\Omega$ equipped with a $\\sigma$-algebra of subsets $\\mathcal{F}$ is called a *measurable space*.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10529cf3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Random Variable and Random Vector**\n",
    "<br>\n",
    "Let $(\\Omega, \\mathcal{F})$ and $(\\mathbb{R}^p, \\mathcal{B}(\\mathbb{R}^p))$ be two measurable spaces.\n",
    "A function $\\boldsymbol{X}: \\Omega \\to \\mathbb{R}^p$ such that the event\n",
    "\n",
    "\\begin{equation}\n",
    "\\{\\omega \\in \\Omega: X_1(\\omega) \\le x_1, \\ldots, X_p(\\omega) \\le x_p\\}\n",
    "=: \\{\\omega \\in \\Omega: \\boldsymbol{X}(\\omega) \\le \\boldsymbol{x}\\}\n",
    "=: \\{\\boldsymbol{X} \\le \\boldsymbol{x}\\}\n",
    "\\end{equation}\n",
    "\n",
    "belongs to $\\mathcal{F}$ for any $\\boldsymbol{x} \\in \\mathbb{R}^p$ is called a *measurable function* or *random vector*.\n",
    "If $p = 1$, $X$ is called a *random variable*.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16775dce",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In other words, the preimage of any Borel set under $\\boldsymbol{X}$ is an event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ebd4bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Distribution Function of a Random Variable**\n",
    "<br>\n",
    "Every random variable from a probability space $(\\Omega, \\mathcal{F}, \\mu)$ to $(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$ induces a probability measure $\\mathbb{P}$ on $\\mathbb{R}$ that we identify with the *probability distribution function* $F_X: \\mathbb{R} \\to [0, 1]$ defined as\n",
    "\n",
    "\\begin{equation}\n",
    "F_X(x) = \\mu(\\omega \\in \\Omega: X(\\omega) \\le x) =: \\mathbb{P}(X \\le x), x \\in \\mathcal{B}(\\mathbb{R}).\n",
    "\\end{equation}\n",
    "\n",
    "In this case, $(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}), F_X)$ becomes a probability space.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd57cf5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "If $X$ is not a measurable function, there exists an $x$ in $\\mathbb{R}$ such that $\\{\\omega \\in \\Omega: X \\le x\\}$ is not an event.\n",
    "Then, $\\mathbb{P}(X \\le x) = \\mu(\\omega \\in \\Omega: X \\le x)$ is not defined and we cannot define the distribution of $X$.\n",
    "This shows that it is the measurability of a random variable that makes it so special.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f84a471",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Joint Distribution Function**\n",
    "<br>\n",
    "Let $X$ and $Y$ be two random variables.\n",
    "We can then define their joint distribution function as\n",
    "\n",
    "\\begin{equation}\n",
    "F_{X, Y}(x, y) = \\mathbb{P}(X \\le x, Y \\le y)\n",
    "\\end{equation}\n",
    "\n",
    "We can view them as a *random vector*, i.e. a random variable from $\\Omega$ to $\\mathbb{R}^2$.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969e1e73",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Independent Random Variables**\n",
    "<br>\n",
    "Two random variables $X$ and $Y$ on $\\mathbb{R}$ are independent if the events $\\{\\omega \\in \\Omega: X(\\omega) \\le x\\}$ and $\\{\\omega \\in \\Omega: Y(\\omega) \\le y\\}$ are independent for all $x, y \\in \\mathbb{R}$.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088faaba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If $X$ and $Y$ are independent then $F_{X, Y}(x, y) = F_X(x)F_Y(y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac23d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Distribution Function of a Random Vector**\n",
    "<br>\n",
    "Every random variable from a probability space $(\\Omega, \\mathcal{F}, \\mu)$ to $(\\mathbb{R}^p, \\mathcal{B}(\\mathbb{R}^p))$ induces a probability measure $\\mathbb{P}$ on $\\mathbb{R}^p$ that we identify with the *distribution function* $F_\\boldsymbol{X}: \\mathbb{R}^p \\to [0, 1]$ defined as\n",
    "\n",
    "\\begin{equation}\n",
    "F_\\boldsymbol{X}(\\boldsymbol{x}) = \\mathbb{P}(\\boldsymbol{X} \\le \\boldsymbol{x}) := \\mu(\\omega \\in \\Omega: \\boldsymbol{X}(\\omega) \\le \\boldsymbol{x}) \\ \\ \\ \\ \\boldsymbol{x} \\in \\mathcal{B}(\\mathbb{R}^p).\n",
    "\\end{equation}\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37417cf6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Expectation of Random Variables**\n",
    "<br>\n",
    "Let $X$ be a random variable from $(\\Omega, \\mathcal{F}, \\mu)$ to $(\\mathbb{R}^p, \\mathcal{B}(\\mathbb{R}^p))$.\n",
    "We define the *expectation* of $\\boldsymbol{X}$ by\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{E}(\\boldsymbol{X}) = \\int_{\\mathbb{R}^p} \\boldsymbol{x} dF_\\boldsymbol{X}(\\boldsymbol{x}).\n",
    "\\end{equation}\n",
    "\n",
    "More generally, let $f: \\mathbb{R}^p \\to \\mathbb{R}$ be measurable.\n",
    "Then\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{E}(f(\\boldsymbol{X})) = \\int_{\\mathbb{R}^p} f(\\boldsymbol{x}) dF_\\boldsymbol{X}(\\boldsymbol{x}).\n",
    "\\end{equation}\n",
    "\n",
    "<hr>\n",
    "\n",
    "$dF_\\boldsymbol{X}(\\boldsymbol{x}) = \\mathbb{P}(d\\boldsymbol{x}) = \\mathbb{P}(dx_1, \\ldots, dx_p)$ and $\\int$ denotes the Lebesgue integral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ef16f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "When $f$ is continuous, the Lebesgue integral can be replaced by the Riemann-Stieltjes integral.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cfc449",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**$L^p$ spaces**\n",
    "<br>\n",
    "By $L^p(\\Omega, \\mathcal{F}, \\mu)$ we mean the Banach space of measurable functions on $\\Omega$ with norm\n",
    "\n",
    "\\begin{equation}\n",
    "\\|X\\|_{L^p} = \\left(E(|X|^p)\\right)^{1/p}.\n",
    "\\end{equation}\n",
    "\n",
    "<hr>\n",
    "\n",
    "In particular, we say that $X$ is integrable if $\\|X\\|_{L^1} < \\infty$ and that $X$ has finite variance if $\\|X\\|_{L^2} < \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc3bba7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Covariance, Variance and Correlation of Two Random Variables**\n",
    "<br>\n",
    "Provided that it exists, we define the *covariance* of two random variables $X$ and $Y$ as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{Cov}(X, Y) := \\mathbb{E}((X - \\mathbb{E}(X)) (Y - \\mathbb{E}(Y)))\n",
    "= \\mathbb{E}(X Y) - \\mathbb{E}(X) \\mathbb{E}(Y).\n",
    "\\end{equation}\n",
    "\n",
    "The *variance* of $X$ is simply\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{Var}(X) := \\mathrm{Cov}(X, X).\n",
    "\\end{equation}\n",
    "\n",
    "The *correlation* of $X$ and $Y$ is\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{Corr}(X, Y) := \\frac{\\mathrm{Cov}(X, Y)}{\\sqrt{\\mathrm{Var}(X)} \\sqrt{\\mathrm{Var}(Y)}}.\n",
    "\\end{equation}\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e0e636",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d19cbd8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Conditional Probability**\n",
    "<br>\n",
    "Let $A$ and $B$ be two events and suppose that $\\mathbb{P}(A) > 0$.\n",
    "The *conditional probability* of $B$ given $A$ is\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{P}(B | A) := \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(A)}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe7fc1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "For random variables, the *conditional probability* of $Y$ knowing $X$ is\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{P}(Y | X) := \\frac{\\mathbb{P}(X \\cap Y)}{\\mathbb{P}(X)}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f939ec8d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Conditional Expectation**\n",
    "<br>\n",
    "Assume that $X \\in L^1(\\Omega, \\mathcal{F}, \\mu)$ and let $\\mathcal{G}$ be a sub-$\\sigma$-algebra of $\\mathcal{F}$.\n",
    "The *conditional expectation* of $\\boldsymbol{X}$ with respect to $\\mathcal{G}$ is the function $\\mathbb{E}(\\boldsymbol{X} | \\mathcal{G}): (\\Omega, \\mathcal{G}) \\to \\mathbb{R}^p$, which is a random variable satisfying\n",
    "\n",
    "\\begin{equation}\n",
    "\\int_G \\mathbb{E}(\\boldsymbol{X} | \\mathcal{G}) d\\mathbb{P} = \\int_G \\boldsymbol{X} d\\mathbb{P} \\ \\ \\ \\ \\forall G \\in \\mathcal{G}.\n",
    "\\end{equation}\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5e568",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It follows that (*law of total expectation*)\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{E}(\\mathbb{E}(\\boldsymbol{X} | \\mathcal{G})) = \\mathbb{E}(\\boldsymbol{X}).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9066a501",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Conditional Distribution Function**\n",
    "<br>\n",
    "Given $\\mathcal{G}$ a sub-$\\sigma$-algebra of $\\mathcal{F}$, we define the *conditional distribution function*\n",
    "\n",
    "\\begin{equation}\n",
    "F_\\boldsymbol{X}(\\boldsymbol{x} | \\mathcal{G}) = \\mathbb{P}(\\boldsymbol{X} \\le \\boldsymbol{x} | \\mathcal{G}) \\ \\ \\ \\ \\forall \\boldsymbol{x} \\in \\mathbb{R}^p.\n",
    "\\end{equation}\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a948c0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Assume that $f: \\mathbb{R}^p \\to \\mathbb{R}$ is such that $\\mathbb{E}(f(X)) < \\infty$.\n",
    "Then\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{E}(f(\\boldsymbol{X}) | \\mathcal{G}) = \\int_{\\mathbb{R}^p} f(\\boldsymbol{x}) dF_\\boldsymbol{X}(\\boldsymbol{x} | \\mathcal{G}).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bcc905",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Conditional Expectation with respect to a Random Vector**\n",
    "<br>\n",
    "The *conditional expectation of $\\boldsymbol{X}$ given $\\boldsymbol{Y}$* is defined by\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{E}(\\boldsymbol{X} | \\boldsymbol{Y}) := \\mathbb{E}(\\boldsymbol{X} | \\sigma(\\boldsymbol{Y})),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\sigma(\\boldsymbol{Y}) := \\{\\boldsymbol{Y}^{-1}(B): B \\in \\mathcal{B}(\\mathbb{R}^p)\\}$ is the *$\\sigma$-algebra generated by $\\boldsymbol{Y}$*.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d9c05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Variance and Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d435247",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Conditional Variance**\n",
    "<br>\n",
    "Suppose that $Y$ is a random variable and that $\\mathcal{G}$ is a sub-$\\sigma$-algebra of $\\mathcal{F}$.\n",
    "Then, the random variable\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{var}(Y | \\mathcal{G}) := \\mathbb{E}[(Y - \\mathbb{E}(Y | \\mathcal{G}))^2 | \\mathcal{G}]\n",
    "\\end{equation}\n",
    "\n",
    "is called the *conditional variance* of $Y$ knowing $\\mathcal{G}$.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15434f08",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It tells us how much variance is left if we use $\\mathbb{E}(Y | \\mathcal{G})$ to predict $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf1b4d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**The Conditional Expectation Minimizes the Least Squares (Th. 10.1.4 in Gut 2005)**\n",
    "<br>\n",
    "Let $X$ and $Y$ be random variables with finite variance, let $g$ be a real-valued function such that $\\mathbb{E}[g(X)^2] < \\infty$.\n",
    "Then\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{E}[(Y - g(X))^2]\n",
    "&= \\mathbb{E}[\\mathrm{Var}(Y | X)] + \\mathbb{E}[(\\mathbb{E}(Y | X) - g(X))^2]\\\\\n",
    "&\\ge \\mathbb{E}[\\mathrm{Var}(Y | X)],\n",
    "\\end{align}\n",
    "\n",
    "where equality is obtained for $g(X) = \\mathbb{E}(Y | X)$.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa04db3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Thus, the expected conditional variance of $Y$ given $X$ shows up as the irreducible error of predicting $Y$ given only the knowledge of $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8356831f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Absolutely Continuous Distributions and Densities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a977ca4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Absolutely Continuous Distribution**\n",
    "<br>\n",
    "A distribution function $F$ is *absolutely continuous* with respect to the Lebesgue measure (denoted $dx$) if and only if there exists a non-negative, Lebesgue integrable function $f$, such that\n",
    "\n",
    "\\begin{equation}\n",
    "F(b) - F(a) = \\int_a^b f(x) dx \\ \\ \\ \\ \\forall a < b.\n",
    "\\end{equation}\n",
    "\n",
    "The function $f$ is called the *density* of $F$ and is denoted by $\\frac{dF}{dx}$.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b8a915",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Equivalently, $F$ is absolutely continuous if and only if, for every measurable set $A$, $dx(A) = 0$ implies $\\mathbb{P}(X \\in A) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997cf40b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Marginal Density**\n",
    "<br>\n",
    "From an absolutely continuous random vector $(X, Y)$ with density $f_{X, Y}$, we can derive the density of $X$, or *marginal density* by integrating over $Y$:\n",
    "\n",
    "\\begin{equation}\n",
    "f_X(x) = \\int_{-\\infty}^\\infty f_{X, Y}(x, y) dy.\n",
    "\\end{equation}\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534bfcb8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If $X$ is an absolutely continuous random variable, with density $f_X$, $g$ is a measurable function, and $\\mathbb{E}(|g(X)|) < \\infty$, then\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{E}(g(X)) = \\int_{-\\infty}^\\infty g(x) f_X(x) dx.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fa9ed6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If $X$ and $Y$ are absolutely continuous, then $X$ and $Y$ are independent if and only if the joint density is equal to the product of the marginal ones, that is\n",
    "\n",
    "\\begin{equation}\n",
    "f_{X, Y}(x, y) = f_X(x) f_Y(y) \\ \\ \\ \\ \\forall x, y \\in \\mathbb{R}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0b7d2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Conditional Density**\n",
    "<br>\n",
    "Let $X$ and $Y$ have a joint absolutely continuous distribution.\n",
    "For $f_X(x) > 0$, the *conditional density* of $Y$ given that $X = x$ equals\n",
    "\n",
    "\\begin{equation}\n",
    "f_{Y | X = x}(y) = \\frac{f_{X, Y}(x, y)}{f_X(x)}\n",
    "\\end{equation}\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56566f41",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then the conditional distribution of $Y$ given that $X = x$ is derived by\n",
    "\n",
    "\\begin{equation}\n",
    "F_{Y | X = x}(y) = \\int_{-\\infty}^y f_{Y | X = x}(z) dz.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6369cc4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If $X$ and $Y$ are independent then the conditional and the unconditional distributions are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f4df1a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "- [Gut, A., 2005. *Probability: A Graduate Course*. Springer, New York.](https://doi.org/10.1007/978-1-4614-4708-5)\n",
    "- [Pavliotis, G.A., 2014. *Stochastic Processes and Applications*. Springer, New York.](https://doi.org/10.1007/978-1-4939-1323-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5a177",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***\n",
    "## Credit\n",
    "\n",
    "[//]: # \"This notebook is part of [E4C Interdisciplinary Center - Education](https://gitlab.in2p3.fr/energy4climate/public/education).\"\n",
    "Contributors include Bruno Deremble and Alexis Tantet.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"display: flex; height: 70px\">\n",
    "    \n",
    "<img alt=\"Logo LMD\" src=\"images/logos/logo_lmd.jpg\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo IPSL\" src=\"images/logos/logo_ipsl.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo E4C\" src=\"images/logos/logo_e4c_final.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo EP\" src=\"images/logos/logo_ep.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo SU\" src=\"images/logos/logo_su.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo ENS\" src=\"images/logos/logo_ens.jpg\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo CNRS\" src=\"images/logos/logo_cnrs.png\" style=\"display: inline-block\"/>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<div style=\"display: flex\">\n",
    "    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0; margin-right: 10px\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a>\n",
    "    <br>This work is licensed under a &nbsp; <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
