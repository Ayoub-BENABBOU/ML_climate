{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb8c31b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tutorial 1 : Python basics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b22f615",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Python is a popular computer language. We will use it along with 4 libraries: numpy for array handeling, pandas for time series, scikit-learn for machine learning tools and matplotlib for ploting. There are *a lot* of ressources on the web: the user manuel remains the primary location where you should look if you are looking for documentation about a specific function. https://stackoverflow.com/ is also a good source of information since many people before you have already had the same question as you. A good intro to numpy: https://sebastianraschka.com/blog/2020/numpy-intro.html\n",
    "\n",
    "Even though python is a great language, don't forget that it is an [Interpreted language](https://en.wikipedia.org/wiki/Interpreter_(computing)). That means that python can be very slow. For this reason you shoud \n",
    "\n",
    "- Avoid loops\n",
    "- Rely on existing libraries when available\n",
    "\n",
    "Indeed, most modern libraries deffer the heavy lifting part to compiled bits of codes which typically run much faster than your own implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d318e1af",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Numpy for array handling\n",
    "\n",
    "Numpy is the core library when it comes to manipulating \"dense\" arrays of numbers and you should always use it instead of raw python lists. Numpy also comes with a couple of linear algebra routines to perform basic operations (matrix multiplication, linear systems, eigenvalue solver). However for large-scale application (and sparse matrices) we will use different libraries (like scipy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79be0bbd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d3360",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Vectors are first declared as a list of number and are then converted to numpy arrays. Note that python does not make the difference between row vectors and column vectors: all vectors are treated as rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d7a0d3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cf12ce",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Matrices are declared as an array of arrays in a similar way as vectors. Note that python is case sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358f4113",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da94a9fa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In order to manipulate row or column vectors, one must add a new dimension as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf2a3085",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "x_col = x[:,None]\n",
    "print(x_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c27bc4",
   "metadata": {},
   "source": [
    "You can compute the transpose of a vector with the method `.T`. However keep in mind that the transpose of a 1d vector does not really make sense *in python*. If you want to transpose a vector in python, it must have at least two dimensions.\n",
    "\n",
    "> ***Question***\n",
    "> - Try to transpose `x` and `x_col` and check their dimensions.\n",
    "- Hint: You can always check the dimensions of your array with the method `.shape`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbdcca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Matrix multiplication can be achieved with `np.dot`, `np.matmul`, `@` or `np.einsum`.\n",
    "> ***Question***\n",
    "> - Pick the one you prefer to compute $\\mathbf A \\mathbf x$, $\\mathbf x \\mathbf x^\\top$, and $\\mathbf x^\\top \\mathbf x$.\n",
    "\n",
    "- Hint: Did I already warned you about transposing 1d vectors in python?\n",
    "- Hint2: Einsum is the most advanced function but also the most complicated. [This tutorial](https://ajcr.net/Basic-guide-to-einsum/) will tell you more about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08bd26b7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac280443",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can access the first element of an array with `x[0]` and the last element with `x[-1]`. You can also select a subset using slices like `x[0:2]` (or `x[:2]`). Be careful that the last index of the slice is not part of the subset.\n",
    "\n",
    "> ***Question***\n",
    "> - Can you select the last two element of the vector $\\mathbf x$ with negative indices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c840f76",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc7f9d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Numpy comes with the standard math function `np.exp`, `np.sqrt`, `np.sin`. Each of these functions applied to an an array is applied element-wise. For instance `A**2` raises each element of `A` to the power of 2.\n",
    "\n",
    "> ***Question***\n",
    "> - Is `A*A` the same as `A@A`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c244bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e918eef6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Broadcasting\n",
    "\n",
    "In python, we can add, subtract, multiply, (etc.) arrays elementwise. In this context arrays have to be of the same size. But when we do `A+1`, we add the scalar `1` to each element of the array `A`: this type of operation is called [broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html). \n",
    "\n",
    "> ***Question***\n",
    "> - Check the broadcasting rules and add `x` to each column of `A`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0481349",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31042ea6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Generating arrays\n",
    "\n",
    "Empty arrays can be generated with `np.zeros`. We can also generate array with [random numbers](https://numpy.org/doc/stable/reference/random/index.html). The most useful functions are `np.random.rand` (unifrom distribution) and `np.random.randn` (normal distribution)\n",
    "\n",
    "> ***Question***\n",
    "> - Generate *one single* array `v` of 2 variables $v_1$ and $v_2$ with $N=500$ observations following the [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) $\\mathcal N (\\mu_1,\\sigma_1^2)$ for $v_1$ and $\\mathcal N (\\mu_2,\\sigma_2^2)$ for $v_2$, with $\\mu_1 = 2$, $\\mu_2 = 1$, $\\sigma_1 = 5$, $\\sigma_2 = 1$\n",
    "- Hint: make sure that the size of `v` is $(500\\times 2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1763a979",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37deb45",
   "metadata": {},
   "source": [
    "The function `np.mean` can be applied to the whole array or to each variable independantly or to  observations. \n",
    "\n",
    "> ***Question***\n",
    "> - Take a look at the documentation of the function that computes the mean to see how to apply it to each dimension.\n",
    "> - Compute the mean of $\\mathbf v = (v_1, v_2)$. You should get a 1d vector of size 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c97944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f292b4e6",
   "metadata": {},
   "source": [
    "> ***Question***\n",
    "> - Do you think $v_1$ and $v_2$ are correlated?\n",
    "> - Recall de definition of the covariance matrix written in vector form. [Hint](https://en.wikipedia.org/wiki/Covariance#Auto-covariance_matrix_of_real_random_vectors)\n",
    "> - Define a matrix `Cv` for the *population* covariance matrix (fill it with $\\sigma_1$ and $\\sigma_2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08dcac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfdea6d",
   "metadata": {},
   "source": [
    "> ***Question***\n",
    "> - Recall de definition of the covariance matrix written in vector form. [Hint](https://en.wikipedia.org/wiki/Covariance#Auto-covariance_matrix_of_real_random_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d802f9",
   "metadata": {},
   "source": [
    "To compute the covariance, you will need to compute (among other things) $E(\\mathbf v \\mathbf v^\\top)$, with $\\mathbf{v}$ a random vector that as $p=2$ features (remember that a vector is a column). However, we have opted to store $N$ different realizations of a random vector in a $(N\\times p)$ matrix. \n",
    "\n",
    "> ***Question***\n",
    "> - Is there an easy way to compute $E(\\mathbf v \\mathbf v^\\top)$ with one single operation?\n",
    "> - Finish to compute the full covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c544a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27f822",
   "metadata": {},
   "source": [
    "\n",
    "> ***Question***\n",
    "> - Check your result by computing the covariance matrix with [`np.cov`](https://numpy.org/doc/stable/reference/generated/numpy.cov.html).\n",
    "\n",
    "\n",
    "Hint: Look at the documentation of `np.cov` to see if the layout convention to compute the covariance is the same as the one we adopted in this class? Do you think the argument `rowvar` could be useful here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "158f9a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0464b7",
   "metadata": {},
   "source": [
    "By now you have probably understood that if you use `np.dot` or `@`, you better adopt the convention to store observations in a $(p\\times N)$ matrix (you probably don't have issues if you use `np.einsum`). Declare a new variable `v_np = v.T`. From now on, if your variables are in `numpy` convention, add `_np` to their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f08aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523493c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As you just saw, $v_1$ and $v_2$ are not correlated. Let's apply the linear transformation\n",
    "\\begin{align}\n",
    "w_1& = \\cos \\theta v_1 - \\sin \\theta v_2\\\\\n",
    "w_2& = \\sin \\theta v_1 + \\cos \\theta v_2\n",
    "\\end{align}\n",
    "That you can also write for each realization\n",
    "\\begin{equation}\n",
    "\\mathbf{w} = \\mathbf{R}\\mathbf{v}\n",
    "\\end{equation}\n",
    "with $\\mathbf R$ the rotation matrix\n",
    "\\begin{align}\n",
    " \\mathbf{R} &= \\begin{bmatrix}\n",
    "    \\cos \\theta & -\\sin \\theta \\\\\n",
    "    \\sin \\theta & \\cos \\theta\n",
    "  \\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "> ***Question***\n",
    "> - Create the rotation matrix `R` with $\\theta=\\pi/3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ca5ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0dc581",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "> ***Question***\n",
    "> - Compute $\\mathbf{w}$ (in one line). Put the result in the variable `w_np`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1dfb8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b454a717",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> ***Question***\n",
    "> - Compute the mean of $\\mathbf w$ with two different techniques: \n",
    ">     - direct computation with `np.mean`  \n",
    ">     - with the mean of $\\mathbf v$. \n",
    "\n",
    "For the second method, you will have to derive the formula from the definition of $\\mathbf w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6689ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944c3677",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> ***Question***\n",
    "> - Can you guess what the covariance between $w_1$ and $w_2$ will be? [Hint](https://en.wikipedia.org/wiki/Covariance#Covariance_of_linear_combinations)\n",
    "> - Compute the theoretical covariance matrix $C_w$ as a function of $R$ and $C_v$ (the covariance matrix of $\\mathbf v$) [Hint](https://en.wikipedia.org/wiki/Covariance#Auto-covariance_matrix_of_real_random_vectors)\n",
    "> - Compute the covariance matrix with the 2 methods: \n",
    ">      - with `np.cov`, \n",
    ">      - with `R` and `Cv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46ff671d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48af9da1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Matplotlib for plotting\n",
    "\n",
    "To vizualize data, matplotlib is the reference tool and it is necessary to know the basics. Matplotlib is also what runs behind the scene of high level python libraries (pandas, xarray) and so knowing the basics will also be useful there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdf13947",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2359a1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> ***Question***\n",
    "> - Can you vizualize the data set `V` that we generated earlier. you can either pass the two variables to the function `plt.plot` in order to plot $v_2$ as a function of $v_1$ or we can use the function `plt.scatter`. Don't forget to \n",
    ">    - adjust the type and size of markers [Hint](https://matplotlib.org/stable/api/markers_api.html)\n",
    ">    - adjust the axis so that both axis are equally stretched [Hint](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/axis_equal_demo.html).\n",
    ">    - add labels [Hint](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xlabel.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22460c68",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e2cc30",
   "metadata": {},
   "source": [
    "> ***Question***\n",
    "> - Do you *see* the lack of correlation between $v_1$ and $v_2$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c041e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's analyze the probability density function (pdf) of this data set. the function [`np.histogram`](https://numpy.org/doc/stable/reference/generated/numpy.histogram.html) provides a discrete estimate of the pdf along a given dimension\n",
    "\n",
    "> ***Question***\n",
    "> - Adjust the number of bins `np.histogram` to compute and plot an estimation of the pdf of $w_1$ and $w_2$.\n",
    "> - ***(Optional)*** Compare it with the analytical probability density function of $w_1$ and $w_2$? ([Hint](https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8d3a6e7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d882462",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can also get a quick overview of the statistical distribution of the data with [box plot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.boxplot.html).\n",
    "\n",
    "> ***Question***\n",
    "> - What is the meaning of a box plot?\n",
    "> - Try it on $w_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a45625",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> ***Question (optional)***\n",
    "> - Use `np.histogram2d` to compute the 2-dimensional pdf\n",
    "> - On a single plot, superimpose the cloud of points and the contour lines of the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c4087b0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc0dd6",
   "metadata": {},
   "source": [
    "> - ***Question (Optional)***: The [Central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) states that If $X_1, X_2,\\dots ,X_{n}$ are $n$ random samples drawn from a population with overall mean  $\\mu$ and finite variance $\\sigma ^{2}$ $\\bar {X}_{n}$ is the sample mean, then the limiting form of the distribution, $Z=\\lim _{n\\to \\infty }{\\sqrt {n}}{\\left({\\frac {{\\bar {X}}_{n}-\\mu }{\\sigma }}\\right)}$ is a standard normal distribution. Can you propose an visual illustration of this theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3794ca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d705a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pandas for advanced array manipulation\n",
    "\n",
    "Compared to numpy which already handles arrays of numbers, Pandas essentially handles **metadata**. This will allow you to use predefined functions in pandas especially when it comes to time series manipulations. \n",
    "\n",
    "Pandas has a lot of other nice features like\n",
    "\n",
    "- Intuitive handeling of missing data (NaN)\n",
    "- Input/output in many formats\n",
    "- Simplified plotting procedures (labels, axes, etc. are added automatically)\n",
    "- Better managment of the memory\n",
    "\n",
    "We are going to explore the basic functionalities of pandas with the historical CO2 measurements taken at Mona Loa also known as the [Keeling curve](https://en.wikipedia.org/wiki/Keeling_Curve). The data can be downloaded at [scrippsco2.ucsd.edu](http://scrippsco2.ucsd.edu) and we are going to analyze the daily output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51c4a8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Take a moment to inspect the file that is located here `data/daily_in_situ_co2_mlo.csv` (either use a text editor or navigate within jupyter to open the file). Read the header to understand what is the data set about (you may have to investigate more to know about the units). \n",
    "\n",
    "> **Question**\n",
    "> - Why is there NaN in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bc9851a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084fbf75",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are going to use the function [`pd.read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) to import the data in python. It is very important to do a clean import of the data so that we can work efficiently afterwards. Pay extra attention to \n",
    "- the commented part in the header (hint: `comment`)\n",
    "- add a name to each column. Use the names **year**, **month**, **day** for the corresponding columns. This way, pandas will directly recognize what they are (hint: `names`)\n",
    "- pandas handles spaces in cvs files in a very specific way: you may need to adjust its behavior with `skipinitialspace`.\n",
    "\n",
    "Use `pd.read_csv` to load the content of `data/daily_in_situ_co2_mlo.csv` into a DataFrame called `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d3c3775",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data/daily_in_situ_co2_mlo.csv', comment='%',names=[\"Year\", \"Month\", \"Day\", \"CO2\", \"NB\", \"scale\"], skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce54df",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To access your data, you will need to know the metadata, i.e. the label of each column in the csv file (in this case provided by yourself). You can get a quick overview of your data by typing `df.head()` or `df.describe()`. You will see that the Dataframe `df` can be treated like a spreadsheet with labeled columns and entries for each column. You can view the labels with `df.columns` and the rows indices with `df.index`. Make sure you understand the type of each column of the dataset with `df.dtypes`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e0853b0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#look at the data set here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79666f34",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can select a column of the DataFrame by passing one name to `df` like `df[\"year\"]`. You can also select multiple columns by passing a list of names `df[[\"year\", \"month\"]]`. To select specific rows, you need to use the method `.loc[]` to which you need to provide the index. In our case we did not provide labels for the indices so pandas automatically numbered the rows with a simple counter.\n",
    "\n",
    "> ***Question***\n",
    "> - Create a new DataFrame that contains only the first 100 entries and with the columns \"year\" and \"co2\" only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e1431d4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d10236",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One killer feature of pandas is the way it handles time series. In order to use the full potential of such tool, one need to change the index to a date that is recognized by pandas. We use [`pd.to_datetime`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) to combine the information in the year, month and day columns of the dataframe. `pd.to_datetime` handles various format as input and you should be careful to use the correct input format. However, because you carefully chose the name of the columns, you can directly assemble the corresponding columns to create a new object. You can follow the method in the [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#assembling-datetime-from-multiple-dataframe-columns) to re-allocate `df.index` to a `datetime` type variable. Henceforth, we will use `df.index` to access the time dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e5274ec",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7346a8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> ***Question (Optional)***\n",
    "> - Note that one could have done this operation directly while reading the data. Use `parse_dates` in `pd.read_csv` to create a datetime object in `df`. Try it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b45e4d4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now `df.index` contain [Timestamp](https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.html)s. You can quickly access the day, month, year of the reccords by using `df.index.day`, `df.index.month` `df.index.year` (etc. see documentation). You can also construct time intervals (or [timedetla](https://pandas.pydata.org/docs/reference/api/pandas.Timedelta.html)s) by subtracting two timestamps\n",
    "\n",
    "> ***Question***\n",
    "> - Subtract the first index to the last index to know how many days are in this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c1a39be",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e030413",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pandas has built-in plotting features that are based on matplotlib. Since you now master matplotlib, you will find it very easy to plot data within pandas. \n",
    "\n",
    "> ***Question***\n",
    "> - Plot the CO2 time series as a function of time. (Hint: select the column of interest in df and simply apply the method `.plot()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60e54eb1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29beed2e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The CO2 curve is increasing. This is not really a surprised if you followed the news lately. However, we also notice wiggely patterns superimposed to this trend. Are we looking at noisy data are does it have a physical meaning?\n",
    "\n",
    "> ***Question***\n",
    "> - In order to get a closer look, can you plot only 2 years of the CO2 time series between Jan 1st 2000 and Jan 1st 2002?\n",
    "\n",
    "In order to achieve this, you need to select the data for wich `df.index >= '2000-01-01'` and `df.index <= '2002-01-01'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01624960",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feb6af3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So there seem to be a lot of variability and many missing data in this data set. We can try to average all available data for each single year that we have. That way we will probably see a smoother curve. The [`resample`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html) function is here to create a new time series with the desired sampling frequency. The accronym for standard time intervals are listed in the [Time series documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases). You need to either add the method `.mean()` or `.sum()` to the resampled data to indicate how to treat the data in the resampling interval.\n",
    "\n",
    "> ***Question***\n",
    "> - Plot the yearly average evolution of the CO2 concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39ecc55d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f38d5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "These wiggles are not random but are the actual annual cycle of the data.\n",
    "> ***Question (Optional)***\n",
    "> - Use the method `.groupby` to plot the annual cycle\n",
    "> - Discuss the physical origin of this anual cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18a7e651",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d54f3c4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Scikit-learn for data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822fc378",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[Scikit-learn](https://scikit-learn.org/) will be our toolbox for all statistical analysis. It provides the most popular machine learning algorithm, is well documented and has an active user community. Scikit learn does not work well with missing data. So in order to have a smooth transition between pandas and scikit-learn, it is convenient to create a copy of your DataFrame without any `NaN`. Make sure you use (and understand) the [`.copy()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.copy.html) method to create the new array because we are going to make modification to this new DataFrame. You can call this new DataFrame `dfv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f8ad71c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f035614",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Because we cannot do a linear regression with dates as indices, we need to create an additional column that contains the day number since the begining of the dataset. Remember how we worked with timedelta (and broadcasting) above?\n",
    "\n",
    "> ***Question***\n",
    "> - Can you create this new column and name it `counter`?\n",
    "\n",
    "*Be careful that this new variable must have dtype int (or float) and not a timedelta. (Hint: look at the [attributes of timedelta](https://pandas.pydata.org/pandas-docs/stable/user_guide/timedeltas.html#attributes))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f09b985",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8460c4a1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are now ready to use the [linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56d470f0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0646dc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are first going to [fit](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.fit) the data. As explained in the documentation, this function takes at least two arguments: the predictors and the observations. Predictors must be a 2d array of shape (n_samples, n_features), **even if there is only ONE feature**. One simple way to achieve this is to select a list of only one variable in the DataFrame (i.e. `dfv[[\"counter\"]]`, note the usage of double brackets here).\n",
    "\n",
    "> ***Question***\n",
    "> - Perform the linear regression and put the output in the variable `reg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d829a84f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c218be8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> ***Question***\n",
    "> - What is the value of the regression coefficient?\n",
    "> - What is its physical meaning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e004f059",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a06f874",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> ***Question***\n",
    "> - Use the method `.predict` to construct the predicted value at all observation times and add it to the `dfv` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6dd18269",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc11ec23",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> ***Question***\n",
    "> - Plot the observed value along with your prediction on a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8411e407",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e77b2e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is now super easy to compute the co2 growth rate in ppm/year for several time periods.\n",
    "> ***Question***\n",
    "> - Perform 2 linear regressions: one between 1960 and 1980 and one between 2000 and 2020 and compare how the growth rate evolved over time.\n",
    "> - Can you give an estimate of the CO2 concentration in 2050?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e186998",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***\n",
    "## Credit\n",
    "\n",
    "[//]: # \"This notebook is part of [E4C Interdisciplinary Center - Education](https://gitlab.in2p3.fr/energy4climate/public/education).\"\n",
    "Contributors include Bruno Deremble and Alexis Tantet.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"display: flex; height: 70px\">\n",
    "    \n",
    "<img alt=\"Logo LMD\" src=\"images/logos/logo_lmd.jpg\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo IPSL\" src=\"images/logos/logo_ipsl.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo E4C\" src=\"images/logos/logo_e4c_final.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo EP\" src=\"images/logos/logo_ep.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo SU\" src=\"images/logos/logo_su.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo ENS\" src=\"images/logos/logo_ens.jpg\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo CNRS\" src=\"images/logos/logo_cnrs.png\" style=\"display: inline-block\"/>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<div style=\"display: flex\">\n",
    "    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0; margin-right: 10px\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a>\n",
    "    <br>This work is licensed under a &nbsp; <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
