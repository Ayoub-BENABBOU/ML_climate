{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b500a8",
   "metadata": {},
   "source": [
    "# Tutorial: Overfitting/Underfitting and Bias/Variance\n",
    "\n",
    "Tutorial to the class [Overfitting/Underfitting and Bias/Variance](3_overfitting_underfitting_bias_variance.ipynb) based on the same case study as in [Tutorial: Supervised Learning Problem and Least Squares](2_tutorial_supervised_learning_problem_ols.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884267e1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Tutorial Objectives</b>\n",
    "    \n",
    "- Evaluate model performance by estimating the Expected Prediction Errors (EPE) using test data\n",
    "- Same as above but with cross-validation\n",
    "- Compute and plot learning curves\n",
    "- Improve the models by modifying the input features\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b50e8",
   "metadata": {},
   "source": [
    "## Getting ready\n",
    "\n",
    "Let us follow the same procedure as in [Tutorial: Supervised Learning Problem and Least Squares](2_tutorial_supervised_learning_problem_ols.ipynb) to import the required modules and read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4b6fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path manipulation module\n",
    "from pathlib import Path\n",
    "# Numerical analysis module\n",
    "import numpy as np\n",
    "# Formatted numerical analysis module\n",
    "import pandas as pd\n",
    "# Plot module\n",
    "import matplotlib.pyplot as plt\n",
    "# Default colors\n",
    "RC_COLORS = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# Set data directory\n",
    "data_dir = Path('data')\n",
    "\n",
    "# Set keyword arguments for pd.read_csv\n",
    "kwargs_read_csv = dict()\n",
    "\n",
    "# Set first and last years\n",
    "FIRST_YEAR = 2014\n",
    "LAST_YEAR = 2019\n",
    "\n",
    "# Define temperature filepath\n",
    "temp_filename = 'surface_temperature_merra2_{}-{}.csv'.format(\n",
    "    FIRST_YEAR, LAST_YEAR)\n",
    "temp_filepath = Path(data_dir, temp_filename)\n",
    "\n",
    "# Define electricity demand filepath\n",
    "dem_filename = 'reseaux_energies_demand_demand.csv'\n",
    "dem_filepath = Path(data_dir, dem_filename)\n",
    "\n",
    "# Read hourly temperature and demand data averaged over each region\n",
    "df_temp_hourly = pd.read_csv(temp_filepath, index_col=0, parse_dates=True, header=0)\n",
    "df_dem_hourly = pd.read_csv(dem_filepath, index_col=0, header=0, parse_dates=True)\n",
    "\n",
    "# Get daily-mean temperature and daily demand\n",
    "df_temp = df_temp_hourly.resample('D').mean()\n",
    "df_dem = df_dem_hourly.resample('D').sum()\n",
    "\n",
    "# Select Île-de-France region\n",
    "region_name = 'Île-de-France'\n",
    "df_temp_idf = df_temp[region_name]\n",
    "df_dem_idf = df_dem[region_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e44c5d",
   "metadata": {},
   "source": [
    "## Estimating the prediction error using a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8563b26",
   "metadata": {},
   "source": [
    "> ***Question***\n",
    "> - Estimate the prediction error (prediction $R^2$) from 1 year of test data for Île-de-France using the other years to train an OLS.\n",
    "> - How does it compare to the train error estimated from the train data?\n",
    "> - Is the prediction $R^2$ an estimate of the expected prediction error or of the prediction error conditioned on some train dataset?\n",
    "> - Do you expect overfitting to have occurred?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2f5cbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_test_days' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0fe2961acce5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Select train set from previous years\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn_test_days\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn_test_days\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_test_days' is not defined"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Prepare input and output for fit\n",
    "X = df_temp_idf.values[:, None]\n",
    "y = df_dem_idf.values\n",
    "\n",
    "# Number of test days\n",
    "n_test = 365\n",
    "\n",
    "# Select test set from last year\n",
    "X_test = X[-n_test:]\n",
    "y_test = y[-n_test:]\n",
    "\n",
    "\n",
    "# Select train set from previous years\n",
    "X_train = X[:-n_test]\n",
    "y_train = y[:-n_test]\n",
    "\n",
    "# Fit model on train data\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "reg.fit(X_train, y_train)\n",
    "print('Estimated coefficients:')\n",
    "print('intercept\\t', reg.intercept_)\n",
    "print('slope\\t\\t', reg.coef_[0])\n",
    "\n",
    "# Get train score\n",
    "r2_train = reg.score(X_train, y_train)\n",
    "print('\\nTrain R2:\\t', r2_train)\n",
    "\n",
    "r2_test = reg.score(X_test, y_test)\n",
    "print('Test R2:\\t', r2_test)\n",
    "\n",
    "plt.scatter(X_train[:, 0], y_train, s=5, alpha=0.5, label='Train data')\n",
    "plt.scatter(X_test[:, 0], y_test, s=5, alpha=1, label='Test data')\n",
    "x = np.linspace(-5., 35., 100)\n",
    "y_pred = reg.predict(x[:, None])\n",
    "plt.plot(x, y_pred, color=RC_COLORS[2], label='Prediction')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7edd55e",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f339cba",
   "metadata": {},
   "source": [
    "> ***Question***\n",
    "> - How does the prediction error changes if it is computed based on the last 3 months of the year instead?\n",
    "> - Give at least 2 reasons to explain these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of test days\n",
    "n_test = 30\n",
    "\n",
    "# Select test set from last year\n",
    "X_test = X[-n_test:]\n",
    "y_test = y[-n_test:]\n",
    "\n",
    "\n",
    "# Select train set from previous years\n",
    "X_train = X[:-n_test]\n",
    "y_train = y[:-n_test]\n",
    "\n",
    "# Fit model on train data\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "reg.fit(X_train, y_train)\n",
    "print('Estimated coefficients:')\n",
    "print('intercept\\t', reg.intercept_)\n",
    "print('slope\\t\\t', reg.coef_[0])\n",
    "\n",
    "# Get train score\n",
    "r2_train = reg.score(X_train, y_train)\n",
    "print('\\nTrain R2:\\t', r2_train)\n",
    "\n",
    "r2_test = reg.score(X_test, y_test)\n",
    "print('Test R2:\\t', r2_test)\n",
    "\n",
    "plt.scatter(X_train[:, 0], y_train, s=5, alpha=0.5, label='Train data')\n",
    "plt.scatter(X_test[:, 0], y_test, s=10, alpha=1, label='Test data')\n",
    "x = np.linspace(-5., 35., 100)\n",
    "y_pred = reg.predict(x[:, None])\n",
    "plt.plot(x, y_pred, color=RC_COLORS[2], label='Prediction')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a090d02",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a1863",
   "metadata": {},
   "source": [
    "### Learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ecf34",
   "metadata": {},
   "source": [
    "> ***Question***\n",
    "> - Compute and plot a learning curve. To do so:\n",
    ">   - Set 1 year of data aside to compute the test error always on the same period\n",
    ">   - Define a list of train period of increasing lengths\n",
    ">   - Loop over these train periods to iteratively:\n",
    ">     - Select data for this train period\n",
    ">     - Train the model\n",
    ">     - Compute the train error from the train data for the train period\n",
    ">     - Compute the test error from the test data for the test period\n",
    ">     - Save both errors\n",
    ">   - Plot both errors curves\n",
    "> - Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get learning curve for a given number of test days\n",
    "def get_learning_curve(X, y, n_test, fit_intercept=True):\n",
    "    X_test = X[-n_test:]\n",
    "    y_test = y[-n_test:]\n",
    "\n",
    "    # Select train set from previous years\n",
    "    X_train = X[:-n_test]\n",
    "    y_train = y[:-n_test]\n",
    "\n",
    "    # Define the number of days by which to increase the train periods\n",
    "    step = 30\n",
    "    n_days = np.arange(step, X_train.shape[0], step)\n",
    "\n",
    "    # Define arrays in which to save the errors\n",
    "    r2_trains = np.empty(n_days.shape)\n",
    "    r2_tests = np.empty(n_days.shape)\n",
    "\n",
    "    # Loop over train periods stopping before overlapping test period\n",
    "    for idx, nd in enumerate(n_days):\n",
    "        # Select for the number of days\n",
    "        X_train_nd = X_train[:nd]\n",
    "        y_train_nd = y_train[:nd]\n",
    "\n",
    "        # Fit\n",
    "        reg = linear_model.LinearRegression(fit_intercept=fit_intercept)\n",
    "        reg.fit(X_train_nd, y_train_nd)\n",
    "\n",
    "        # Get the train score\n",
    "        r2_train = reg.score(X_train_nd, y_train_nd)\n",
    "\n",
    "        # Get the test score\n",
    "        r2_test = reg.score(X_test, y_test)\n",
    "\n",
    "        r2_trains[idx] = r2_train\n",
    "        r2_tests[idx] = r2_test\n",
    "\n",
    "\n",
    "    # Plot the learning curves\n",
    "    plt.figure()\n",
    "    plt.plot(n_days, r2_trains, label='Train R2')\n",
    "    plt.plot(n_days, r2_tests, label='Test R2')\n",
    "    plt.ylim(0., 1.)\n",
    "    plt.legend()\n",
    "    \n",
    "\n",
    "# Select test set from last year\n",
    "N_TEST = 365\n",
    "\n",
    "# Prepare input and output for fit\n",
    "X = df_temp_idf.values[:, None]\n",
    "y = df_dem_idf.values\n",
    "\n",
    "\n",
    "get_learning_curve(X, y, N_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1452b7a6",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264fb69",
   "metadata": {},
   "source": [
    "> ***Question***\n",
    "> - Same question as above but for 2 years of test data. Compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5866c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TEST = 365 * 2\n",
    "get_learning_curve(X, y, N_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceadeea3",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536677a7",
   "metadata": {},
   "source": [
    "## Estimating the expected prediction error with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96af599",
   "metadata": {},
   "source": [
    "> ***Question***\n",
    "> - Perform a $k$-fold cross-validation of your own by repeating the above estimation of the test error on all years. To do so:\n",
    ">   - Use the `split` method of a `sklearn.model_selection.KFold` object initialized with the `n_splits` option to get a sequence train and test indices over which to loop.\n",
    ">   - For each pair of train and test indices:\n",
    ">     - Select the train and test data from the input and output data;\n",
    ">     - Fit the model using the train data;\n",
    ">     - Use the fitted model to predict the target from the test inputs;\n",
    ">     - Estimate the $R^2$ from the test output.\n",
    ">   - Average the $R^2$ estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a8db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Number of splits\n",
    "N_SPLITS = len(df_temp) // 365\n",
    "\n",
    "# Define k-fold iterator\n",
    "kf = KFold(n_splits=N_SPLITS)\n",
    "\n",
    "# Loop over the train and test indices\n",
    "r2_test_arr = np.empty((N_SPLITS,))\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    # Select the train and test inputs\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "\n",
    "    # Select the train and test targets\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Fit the OLS model using the train data\n",
    "    reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the test target\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    # Compute test R2\n",
    "    r2_test_arr[i] = reg.score(X_test, y_test)\n",
    "\n",
    "# Average R2 and print\n",
    "r2_test_mean = np.mean(r2_test_arr)\n",
    "print('List of R2:', r2_test_arr)\n",
    "print('Average test R2:', r2_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e1b0d",
   "metadata": {},
   "source": [
    "> ***Question***\n",
    "> - Verify your results using the `cross_val_score` function of `sklearn.model_selection` with the appropriate value for the `cv` option.\n",
    "> - How does the $R^2$ estimate from the cross-validation compare to your estimation above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc17f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit-learn cross-validation function\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "r2_test_arr = cross_val_score(reg, X, y, cv=N_SPLITS)\n",
    "r2_test_mean = np.mean(r2_test_arr)\n",
    "print('List of R2:', r2_test_arr)\n",
    "print('Average test R2:', r2_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b2cb6c",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2331a8",
   "metadata": {},
   "source": [
    "## Improving the linear model by adding features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2619fcbc",
   "metadata": {},
   "source": [
    "We know from consumer behavior and heating technologies that individual heating tends to increase linearly from no heating below some heating temperature $T_H \\approx 15$°C.\n",
    "\n",
    "> ***Question***\n",
    "> - Design two input variables that reflect this behavior.\n",
    "> - Fit the two-dimensional linear model and plot its predictions.\n",
    "> - Compute the train and test learning curves for this model.\n",
    "> - Compare the results to the one-dimensional model and explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a2bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heating-temperature threshold\n",
    "TEMP_HEAT = 15.\n",
    "\n",
    "# Since we give the base, we won't fit the intercept\n",
    "FIT_INTERCEPT = False\n",
    "\n",
    "# Define function returning a dictionary from variable name\n",
    "# to variable train data with base and heating variables\n",
    "def get_base_heat(x):\n",
    "    return {\n",
    "        'base': np.ones(x.shape),\n",
    "        'heat': (TEMP_HEAT - x) * (x < TEMP_HEAT).astype(float)\n",
    "    }\n",
    "\n",
    "# Define function to fit and plot piecewise linear regression\n",
    "def fit_piecewise_linear(get_variables, x_train, y_train, x_test):\n",
    "    # Get variables to train\n",
    "    variables_train = get_variables(x_train)\n",
    "    \n",
    "    # Create input matrix with a column for each variable\n",
    "    X_train = np.empty((len(x_train), len(variables_train)))\n",
    "    \n",
    "    # Loop over train variables pair\n",
    "    plt.figure()\n",
    "    for i, (variable_name, variable_data) in enumerate(\n",
    "        variables_train.items()):\n",
    "        # Add variable data to input matrix\n",
    "        X_train[:, i] = variable_data\n",
    "        \n",
    "        # Plot variable\n",
    "        plt.scatter(x_train, variable_data, label=variable_name, s=5)\n",
    "     \n",
    "    # Fit OLS\n",
    "    reg = linear_model.LinearRegression(fit_intercept=FIT_INTERCEPT)\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Get variables to test\n",
    "    variables_test = get_variables(x_test)\n",
    "    \n",
    "    # Create input matrix with a column for each variable\n",
    "    X_test = np.empty((len(x_test), len(variables_test)))\n",
    "    \n",
    "    # Loop over train variables pair\n",
    "    for i, (variable_name, variable_data) in enumerate(\n",
    "        variables_test.items()):\n",
    "        # Add variable data to input matrix\n",
    "        X_test[:, i] = variable_data\n",
    "        \n",
    "    # Get prediction from test input\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    # Plot prediction over train data\n",
    "    plt.figure()\n",
    "    plt.scatter(x_train, y_train, s=5, alpha=0.5)\n",
    "    plt.plot(x_test, y_pred, color=RC_COLORS[1])\n",
    "    \n",
    "    # Get learning curve without fitting intercept\n",
    "    N_TEST = 365 * 2\n",
    "    get_learning_curve(X_train, y_train, N_TEST, fit_intercept=FIT_INTERCEPT)\n",
    "    \n",
    "# Prepare input and target to train\n",
    "x_train = df_temp_idf.values\n",
    "y_train = df_dem_idf.values\n",
    "\n",
    "# Define input test data\n",
    "x_test = np.linspace(-5., 35., 100)\n",
    "\n",
    "fit_piecewise_linear(get_base_heat, x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e6a9d",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c4ef9",
   "metadata": {},
   "source": [
    "In southern regions where climates are relatively warm, air conditioning may be used when daily-mean temperatures increase above about 20°C.\n",
    "As a result, regional electricity demand increases somewhat linearly above this threshold.\n",
    "\n",
    "> ***Question***\n",
    "> - Add a third input variable to reflect this behavior apply and validate the model to the `\"Provence-Alpes-Côte d'Azur\"` region.\n",
    "> - Compare the skills of the 1, 2 and 3-dimensional models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96834e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cooling-temperature threshold\n",
    "TEMP_COOL = 20.\n",
    "\n",
    "# Define function returning a dictionary from variable name\n",
    "# to variable train data with base, heating and cooling variables\n",
    "def get_base_heat_cool(x):\n",
    "    return {\n",
    "        'base': np.ones(x.shape),\n",
    "        'heat': (TEMP_HEAT - x) * (x < TEMP_HEAT).astype(float),\n",
    "        'cool': (x - TEMP_COOL) * (x > TEMP_COOL).astype(float)\n",
    "    }\n",
    "\n",
    "# Select data for given region\n",
    "region_name = \"Provence-Alpes-Côte d'Azur\"\n",
    "df_temp_reg = df_temp[region_name]\n",
    "df_dem_reg = df_dem[region_name]\n",
    "\n",
    "# Prepare input and target to train\n",
    "x_train = df_temp_reg.values\n",
    "y_train = df_dem_reg.values\n",
    "\n",
    "# Heat-only model\n",
    "fit_piecewise_linear(lambda x: {'intercept': np.ones(x.shape), 'slope': x},\n",
    "                     x_train, y_train, x_test)\n",
    "\n",
    "# Heat and base model\n",
    "fit_piecewise_linear(get_base_heat, x_train, y_train, x_test)\n",
    "\n",
    "# Heat, base and cool model\n",
    "fit_piecewise_linear(get_base_heat_cool, x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ac18b",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c467e84a",
   "metadata": {},
   "source": [
    "***\n",
    "## Credit\n",
    "\n",
    "[//]: # \"This notebook is part of [E4C Interdisciplinary Center - Education](https://gitlab.in2p3.fr/energy4climate/public/education).\"\n",
    "Contributors include Bruno Deremble and Alexis Tantet.\n",
    "Several slides and images are taken from the very good [Scikit-learn course](https://inria.github.io/scikit-learn-mooc/).\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"display: flex; height: 70px\">\n",
    "    \n",
    "<img alt=\"Logo LMD\" src=\"images/logos/logo_lmd.jpg\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo IPSL\" src=\"images/logos/logo_ipsl.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo E4C\" src=\"images/logos/logo_e4c_final.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo EP\" src=\"images/logos/logo_ep.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo SU\" src=\"images/logos/logo_su.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo ENS\" src=\"images/logos/logo_ens.jpg\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo CNRS\" src=\"images/logos/logo_cnrs.png\" style=\"display: inline-block\"/>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<div style=\"display: flex\">\n",
    "    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0; margin-right: 10px\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a>\n",
    "    <br>This work is licensed under a &nbsp; <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
